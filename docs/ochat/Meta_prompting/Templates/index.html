<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Templates (ochat.Meta_prompting.Templates)</title><meta charset="utf-8"/><link rel="stylesheet" href="../../../odoc.support/odoc.css"/><meta name="generator" content="odoc 3.1.0"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><script src="../../../odoc.support/highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script><script>let base_url = '../../../';
let search_urls = ['../../db.js','../../../sherlodoc.js'];
</script><script src="../../../odoc.support/odoc_search.js" defer="defer"></script></head><body class="odoc"><nav class="odoc-nav"><a href="../index.html">Up</a> ‚Äì <a href="../../../index.html">Index</a> &#x00BB; <a href="../../index.html">ochat</a> &#x00BB; <a href="../index.html">Meta_prompting</a> &#x00BB; Templates</nav><div class="odoc-search"><div class="search-inner"><input class="search-bar" placeholder="üîé Type '/' to search..."/><div class="search-snake"></div><div class="search-result"></div></div></div><header class="odoc-preamble"><h1>Module <code><span>Meta_prompting.Templates</span></code></h1><p>Bundled prompt templates and integration guardrails.</p><p>The *meta-prompting* subsystem needs a handful of rather lengthy prompt texts that are sent as *system* or *developer* messages to a Large Language Model (LLM). Storing those texts in external files would introduce I/O at startup and brittle run-time path-search logic. Therefore the canonical versions are embedded directly into the compiled binary and exposed via three constants.</p><p>Each constant contains a fully-formed prompt including headline, task description, required output sections and helpful snippets. All texts are strictly ASCII ‚Äì this avoids encoding issues when they are serialised to JSON and shipped over HTTP.</p><p>Override strategy: higher-level helpers such as <a href="../Prompt_factory/index.html"><code>Meta_prompting.Prompt_factory</code></a> allow callers to replace the embedded templates with custom ones at run-time. The constants below therefore serve as **defaults** rather than hard-wired mandates.</p></header><div class="odoc-content"><div class="odoc-spec"><div class="spec value anchored" id="val-iteration_prompt_v2"><a href="#val-iteration_prompt_v2" class="anchor"></a><code><span><span class="keyword">val</span> iteration_prompt_v2 : string</span></code></div><div class="spec-doc"><p>Full text of the *Prompt Iteration and Optimisation ‚Äì version 2* template.</p><p>Typical usage ‚Äî send as *system* message to an LLM that shall act as a *prompt optimiser*:</p><pre class="language-ocaml"><code>  let open Openai.Chat in
  create
    ~model:&quot;gpt-5&quot;
    ~messages:[ `System Meta_prompting.Templates.iteration_prompt_v2
               ; `User   (Prompt.to_string current_prompt)
               ] ()</code></pre><p>The template asks the model to ‚ù∂ diagnose issues in <code>CURRENT_PROMPT</code>, ‚ù∑ emit a minimal edit list and ‚ù∏ return a revised version that meets the supplied success criteria. See <code>./docs-src/meta_prompting/templates.doc.md</code> for a detailed walk- through of every section.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-generator_prompt_v2"><a href="#val-generator_prompt_v2" class="anchor"></a><code><span><span class="keyword">val</span> generator_prompt_v2 : string</span></code></div><div class="spec-doc"><p>Full text of the *Prompt Pack Generator ‚Äì version 2* template.</p><p>Whereas <a href="#val-iteration_prompt_v2"><code>iteration_prompt_v2</code></a> *fixes* an existing prompt, this template *creates* a production-ready prompt pack from scratch given structured metadata such as <code>GOAL</code>, <code>DOMAIN</code> and <code>STOP_CONDITIONS</code>.</p><p>The resulting pack encompasses: ‚Ä¢ a system prompt ‚Ä¢ assistant rules ‚Ä¢ tool preambles ‚Ä¢ agentic controls ‚Ä¢ context-gathering rules and safety guardrails</p><ul class="at-tags"><li class="see"><span class="at-tag">see</span> <a href="docs-src/meta_prompting/templates.doc.md" class="value">docs-src/meta_prompting/templates.doc.md</a> <p>for an in-depth description and example output.</p></li></ul></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-system_prompt_guardrails"><a href="#val-system_prompt_guardrails" class="anchor"></a><code><span><span class="keyword">val</span> system_prompt_guardrails : string</span></code></div><div class="spec-doc"><p>Repository-wide integration guardrails.</p><p>A short system prompt fragment that reminds downstream agents of the *OChat* tool contract: precedence rules, tool-calling constraints, formatting requirements and context-gathering best practices. Prepend this string to any bespoke system prompt when you need to ensure compatibility with the chat-agent harness.</p><p>Example:</p><pre class="language-ocaml"><code>  let combined_system_prompt =
    Meta_prompting.Templates.system_prompt_guardrails ^ &quot;\n&quot; ^ my_custom_prompt</code></pre></div></div></div></body></html>
