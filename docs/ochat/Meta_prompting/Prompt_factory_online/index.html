<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Prompt_factory_online (ochat.Meta_prompting.Prompt_factory_online)</title><meta charset="utf-8"/><link rel="stylesheet" href="../../../odoc.support/odoc.css"/><meta name="generator" content="odoc 3.1.0"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><script src="../../../odoc.support/highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script><script>let base_url = '../../../';
let search_urls = ['../../db.js','../../../sherlodoc.js'];
</script><script src="../../../odoc.support/odoc_search.js" defer="defer"></script></head><body class="odoc"><nav class="odoc-nav"><a href="../index.html">Up</a> â€“ <a href="../../../index.html">Index</a> &#x00BB; <a href="../../index.html">ochat</a> &#x00BB; <a href="../index.html">Meta_prompting</a> &#x00BB; Prompt_factory_online</nav><div class="odoc-search"><div class="search-inner"><input class="search-bar" placeholder="ðŸ”Ž Type '/' to search..."/><div class="search-snake"></div><div class="search-result"></div></div></div><header class="odoc-preamble"><h1>Module <code><span>Meta_prompting.Prompt_factory_online</span></code></h1><p>Online helpers for prompt generation and iteration.</p></header><div class="odoc-tocs"><nav class="odoc-toc odoc-local-toc"><ul><li><a href="#overview">Overview</a></li><li><a href="#runtime-expectations">Runtime expectations</a></li><li><a href="#behaviour-overrides">Behaviour overrides</a></li></ul></nav></div><div class="odoc-content"><h2 id="overview"><a href="#overview" class="anchor"></a>Overview</h2><p><code>Prompt_factory_online</code> is a *thin* wrapper around OpenAIâ€™s experimental <code>/v1/responses</code> endpoint. It implements the online branch of the promptâ€“engineering feedback loop used by <a href="../index.html"><code>Meta_prompting</code></a> and purposefully exposes a **minimal** surface:</p><ul><li><a href="#val-extract_section"><code>extract_section</code></a></li><li><a href="#val-iterate_revised_prompt"><code>iterate_revised_prompt</code></a></li><li><a href="#val-create_pack_online"><code>create_pack_online</code></a></li></ul><p>All three functions are **pure** from the callerâ€™s perspective â€“ they never raise and signal failure by returning <code>None</code>. Any network access, file I/O or logging stays inside the implementation.</p><h2 id="runtime-expectations"><a href="#runtime-expectations" class="anchor"></a>Runtime expectations</h2><p>â€¢ <code>OPENAI_API_KEY</code> â€“ must be present for the HTTP calls to succeed. â€¢ Optional template overrides are looked up relative to the current working directory:</p><ul><li><code>meta-prompt/templates/iteration_prompt_v2.txt</code></li><li><code>meta-prompt/templates/generator_prompt_v2.txt</code></li></ul><p>â€¢ Repository-wide guard-rails are appended from <code>meta-prompt/integration/system_prompt_guardrails.txt</code> when the file exists; otherwise a baked-in fallback is used.</p><h2 id="behaviour-overrides"><a href="#behaviour-overrides" class="anchor"></a>Behaviour overrides</h2><p>Many defaults (reasoning effort, domain, markdown policy, â€¦) can be tuned without recompilation via a keyâ€“value file referenced by the <code>META_PROMPT_ONLINE_CONFIG</code> environment variable. See <code>load_kv_overrides</code> in the implementation for the exhaustive key list.</p><div class="odoc-spec"><div class="spec value anchored" id="val-extract_section"><a href="#val-extract_section" class="anchor"></a><code><span><span class="keyword">val</span> extract_section : <span><span class="label">text</span>:string <span class="arrow">&#45;&gt;</span></span> <span><span class="label">section</span>:string <span class="arrow">&#45;&gt;</span></span> <span>string option</span></span></code></div><div class="spec-doc"><p><code>extract_section ~text ~section</code> searches <code>text</code> for a heading named <code>section</code> (including the trailing newline) and returns the body of the first match.</p><p>A heading must start at the beginning of a line. The returned slice extends to the next recognised heading â€“ <i>Overview</i>, <i>Revised_Prompt</i>, etc. â€“ or to the end of the string. Leading and trailing whitespace is stripped. If the section is missing or empty the function returns <code>None</code>.</p><p>Example extracting the *Revised_Prompt* section:</p><pre class="language-ocaml"><code>  let txt =
    &quot;Overview\nfoo\nRevised_Prompt\nbar\nIssues_Found\nbaz&quot; in
  assert (
    extract_section ~text:txt ~section:&quot;Revised_Prompt\n&quot; = Some &quot;bar&quot;)</code></pre></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-iterate_revised_prompt"><a href="#val-iterate_revised_prompt" class="anchor"></a><code><span><span class="keyword">val</span> iterate_revised_prompt : 
  <span><span class="label">env</span>:<span class="xref-unresolved">Eio_unix</span>.Stdenv.base <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">goal</span>:string <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">current_prompt</span>:string <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">proposer_model</span>:<span><a href="../../Openai/Responses/Request/index.html#type-model">Openai.Responses.Request.model</a> option</span> <span class="arrow">&#45;&gt;</span></span>
  <span>string option</span></span></code></div><div class="spec-doc"><p><code>iterate_revised_prompt ~env ~goal ~current_prompt ?proposer_model</code> ask the model to produce an improved version of <code>current_prompt</code> given <code>goal</code>.</p><p>The helper:</p><ol><li>loads <code>iteration_prompt_v2.txt</code> from <code>meta-prompt/templates</code> or falls back to <a href="../Templates/index.html#val-iteration_prompt_v2"><code>Templates.iteration_prompt_v2</code></a>;</li><li>appends the repository-wide guard-rail snippet;</li><li>sends a single blocking request through <a href="../../Openai/Responses/index.html#val-post_response"><code>Openai.Responses.post_response</code></a>;</li><li>extracts the *Revised_Prompt* payload with <a href="#val-extract_section"><code>extract_section</code></a>.</li></ol><p>Return value:</p><ul><li><code>Some revised</code> â€“ success;</li><li><code>None</code> â€“ missing API key, transport error, malformed JSON or the absence of a *Revised_Prompt* section.</li></ul><p>All exceptions are caught, logged with <a href="../../Log/index.html#val-emit"><code>Log.emit</code></a> at <code>`Debug</code> and translated to <code>None</code> so the caller can easily fall back to an offline strategy.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-create_pack_online"><a href="#val-create_pack_online" class="anchor"></a><code><span><span class="keyword">val</span> create_pack_online : 
  <span><span class="label">env</span>:<span class="xref-unresolved">Eio_unix</span>.Stdenv.base <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">agent_name</span>:string <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">goal</span>:string <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">proposer_model</span>:<span><a href="../../Openai/Responses/Request/index.html#type-model">Openai.Responses.Request.model</a> option</span> <span class="arrow">&#45;&gt;</span></span>
  <span>string option</span></span></code></div><div class="spec-doc"><p><code>create_pack_online ~env ~agent_name ~goal ?proposer_model</code> generate a *fresh* prompt-pack for <code>agent_name</code>.</p><p>Implementation details mirror <a href="#val-iterate_revised_prompt"><code>iterate_revised_prompt</code></a> but the system prompt is seeded with <code>generator_prompt_v2.txt</code>/<code>!Templates.generator_prompt_v2</code>. The assistant output â€“ typically a multi-section Markdown document â€“ is returned **verbatim** so that callers can post-process it however they see fit.</p><p>Returns <code>None</code> under the same failure conditions as <a href="#val-iterate_revised_prompt"><code>iterate_revised_prompt</code></a>.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-get_iterate_system_prompt"><a href="#val-get_iterate_system_prompt" class="anchor"></a><code><span><span class="keyword">val</span> get_iterate_system_prompt : <span><span class="xref-unresolved">Eio_unix</span>.Stdenv.base <span class="arrow">&#45;&gt;</span></span> string</span></code></div></div></div></body></html>
