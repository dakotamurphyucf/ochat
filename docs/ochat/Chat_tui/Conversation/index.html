<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>Conversation (ochat.Chat_tui.Conversation)</title><meta charset="utf-8"/><link rel="stylesheet" href="../../../odoc.support/odoc.css"/><meta name="generator" content="odoc 3.1.0"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><script src="../../../odoc.support/highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script><script>let base_url = '../../../';
let search_urls = ['../../db.js','../../../sherlodoc.js'];
</script><script src="../../../odoc.support/odoc_search.js" defer="defer"></script></head><body class="odoc"><nav class="odoc-nav"><a href="../index.html">Up</a> â€“ <a href="../../../index.html">Index</a> &#x00BB; <a href="../../index.html">ochat</a> &#x00BB; <a href="../index.html">Chat_tui</a> &#x00BB; Conversation</nav><div class="odoc-search"><div class="search-inner"><input class="search-bar" placeholder="ðŸ”Ž Type '/' to search..."/><div class="search-snake"></div><div class="search-result"></div></div></div><header class="odoc-preamble"><h1>Module <code><span>Chat_tui.Conversation</span></code></h1></header><div class="odoc-content"><div class="odoc-spec"><div class="spec module anchored" id="module-Res_item"><a href="#module-Res_item" class="anchor"></a><code><span><span class="keyword">module</span> Res_item</span><span> = <a href="../../Openai/Responses/Item/index.html">Openai.Responses.Item</a></span></code></div></div><p>Transform OpenAI response items into plain chat messages that the rendering layer can print.</p><p>The module is deliberately tiny: it only concerns itself with *pure* data munging â€“ no I/O, no state â€“ so it can be reused by the model, the renderer and the persistence layer without introducing additional dependencies.</p><p><b>Safety measures</b></p><p>â€¢ Every returned string passes through <a href="../Util/index.html#val-sanitize"><code>Chat_tui.Util.sanitize</code></a> to eliminate control characters that could break the terminal.</p><p>â€¢ Tool output longer than <b>2 000</b> bytes is truncated and marked with an explicit ellipsis. This prevents the UI from freezing on huge JSON payloads.</p><p><b>Relation to <a href="../Types/index.html"><code>Types</code></a></b></p><p>The result type <a href="../Types/index.html#type-message"><code>Types.message</code></a> matches the expectations of <a href="../Model/index.html#type-t.messages"><code>Chat_tui.Model.t.messages</code></a> and ultimately the renderer, so the conversion can be fed directly into the UI without further processing.</p><div class="odoc-spec"><div class="spec value anchored" id="val-pair_of_item"><a href="#val-pair_of_item" class="anchor"></a><code><span><span class="keyword">val</span> pair_of_item : <span><a href="../../Openai/Responses/Item/index.html#type-t">Res_item.t</a> <span class="arrow">&#45;&gt;</span></span> <span><a href="../Types/index.html#type-message">Types.message</a> option</span></span></code></div><div class="spec-doc"><p><code>pair_of_item item</code> converts an OpenAI chat <code>item</code> into a renderable <code>message</code>. Control characters are replaced with spaces and leading / trailing whitespace removed.</p><ul class="at-tags"><li class="returns"><span class="at-tag">returns</span> <p><code>Some (role, content)</code> for items that carry textual content and <code>None</code> for artefacts that cannot be shown in the chat transcript (e.g. progress markers).</p></li></ul><p>Example</p><p>Mapping a single assistant response into the UI format:</p><pre class="language-ocaml"><code>  let it = Openai.Responses.Item.Output_message
             { role = Assistant
             ; content = [ { text = &quot;Hi&quot; } ]
             } in
  assert (Option.value_exn (Chat_tui.Conversation.pair_of_item it)
          = (&quot;assistant&quot;, &quot;Hi&quot;))</code></pre></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-of_history"><a href="#val-of_history" class="anchor"></a><code><span><span class="keyword">val</span> of_history : <span><span><a href="../../Openai/Responses/Item/index.html#type-t">Res_item.t</a> list</span> <span class="arrow">&#45;&gt;</span></span> <span><a href="../Types/index.html#type-message">Types.message</a> list</span></span></code></div><div class="spec-doc"><p><code>of_history items</code> maps <a href="#val-pair_of_item"><code>pair_of_item</code></a> over <code>items</code>, discarding elements that cannot be rendered. The original order is preserved so the resulting list aligns with the OpenAI response indices.</p></div></div></div></body></html>
