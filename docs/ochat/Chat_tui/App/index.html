<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"><head><title>App (ochat.Chat_tui.App)</title><meta charset="utf-8"/><link rel="stylesheet" href="../../../odoc.support/odoc.css"/><meta name="generator" content="odoc 3.1.0"/><meta name="viewport" content="width=device-width,initial-scale=1.0"/><script src="../../../odoc.support/highlight.pack.js"></script><script>hljs.initHighlightingOnLoad();</script><script>let base_url = '../../../';
let search_urls = ['../../db.js','../../../sherlodoc.js'];
</script><script src="../../../odoc.support/odoc_search.js" defer="defer"></script></head><body class="odoc"><nav class="odoc-nav"><a href="../index.html">Up</a> â€“ <a href="../../../index.html">Index</a> &#x00BB; <a href="../../index.html">ochat</a> &#x00BB; <a href="../index.html">Chat_tui</a> &#x00BB; App</nav><div class="odoc-search"><div class="search-inner"><input class="search-bar" placeholder="ðŸ”Ž Type '/' to search..."/><div class="search-snake"></div><div class="search-result"></div></div></div><header class="odoc-preamble"><h1>Module <code><span>Chat_tui.App</span></code></h1><p>Terminal chat application â€“ event-loop, streaming, export, and persistence.</p><p><a href="#"><code>Chat_tui.App</code></a> is the orchestration layer that powers the Ochat terminal UI.</p><p>It wires together:</p><ul><li><a href="../Model/index.html"><code>Chat_tui.Model</code></a> for mutable UI state</li><li><a href="../Controller/index.html"><code>Chat_tui.Controller</code></a> for key handling</li><li><a href="../Renderer/index.html"><code>Chat_tui.Renderer</code></a> for full-screen rendering</li><li><a href="../../Notty_eio/Term/index.html"><code>Notty_eio.Term</code></a> for terminal IO</li><li><a href="../../Chat_response/Driver/index.html"><code>Chat_response.Driver</code></a> for OpenAI streaming and tool execution</li><li><a href="../../Context_compaction/Compactor/index.html"><code>Context_compaction.Compactor</code></a> for user-triggered history compaction</li></ul><p>Use <a href="#val-run_chat"><code>run_chat</code></a> to boot the UI and block until the user quits.</p><p>Most callers should treat everything other than <a href="#val-run_chat"><code>run_chat</code></a> as test-support: these helpers are exposed to enable white-box unit and integration tests of the event-loop and streaming behaviour.</p></header><div class="odoc-content"><div class="odoc-spec"><div class="spec type anchored" id="type-prompt_context"><a href="#type-prompt_context" class="anchor"></a><code><span><span class="keyword">type</span> prompt_context</span><span> = </span><span>{</span></code><ol><li id="type-prompt_context.cfg" class="def record field anchored"><a href="#type-prompt_context.cfg" class="anchor"></a><code><span>cfg : <a href="../../Chat_response/Config/index.html#type-t">Chat_response.Config.t</a>;</span></code><div class="def-doc"><span class="comment-delim">(*</span><p>Behavioural settings (temperature, â€¦)</p><span class="comment-delim">*)</span></div></li><li id="type-prompt_context.tools" class="def record field anchored"><a href="#type-prompt_context.tools" class="anchor"></a><code><span>tools : <span><a href="../../Openai/Responses/Request/Tool/index.html#type-t">Openai.Responses.Request.Tool.t</a> list</span>;</span></code><div class="def-doc"><span class="comment-delim">(*</span><p>Tools exposed to the assistant at runtime.</p><span class="comment-delim">*)</span></div></li><li id="type-prompt_context.tool_tbl" class="def record field anchored"><a href="#type-prompt_context.tool_tbl" class="anchor"></a><code><span>tool_tbl : <span><span>(string, <span>string <span class="arrow">&#45;&gt;</span></span> <a href="../../Openai/Responses/Tool_output/Output/index.html#type-t">Openai.Responses.Tool_output.Output.t</a>)</span>
             <span class="xref-unresolved">Base</span>.Hashtbl.t</span>;</span></code><div class="def-doc"><span class="comment-delim">(*</span><p>Mapping <code>tool_name -&gt; implementation</code>.</p><span class="comment-delim">*)</span></div></li></ol><code><span>}</span></code></div><div class="spec-doc"><p>Runtime artefacts derived from the static chat prompt.</p></div></div><div class="odoc-spec"><div class="spec type anchored" id="type-persist_mode"><a href="#type-persist_mode" class="anchor"></a><code><span><span class="keyword">type</span> persist_mode</span><span> = </span><span>[ </span></code><ol><li id="type-persist_mode.Always" class="def variant constructor anchored"><a href="#type-persist_mode.Always" class="anchor"></a><code><span>| </span><span>`Always</span></code></li><li id="type-persist_mode.Never" class="def variant constructor anchored"><a href="#type-persist_mode.Never" class="anchor"></a><code><span>| </span><span>`Never</span></code></li><li id="type-persist_mode.Ask" class="def variant constructor anchored"><a href="#type-persist_mode.Ask" class="anchor"></a><code><span>| </span><span>`Ask</span></code></li></ol><code><span> ]</span></code></div><div class="spec-doc"><p>Persistence policy to use when the UI terminates.</p><p>The value controls whether a <a href="../../Session/index.html#type-t"><code>Session.t</code></a> snapshot derived from the final <a href="../Model/index.html#type-t"><code>Model.t</code></a> is written back to disk at the end of <a href="#val-run_chat"><code>run_chat</code></a>. The policy is ignored when no <code>session</code> was supplied.</p></div></div><div class="odoc-spec"><div class="spec value anchored" id="val-run_chat"><a href="#val-run_chat" class="anchor"></a><code><span><span class="keyword">val</span> run_chat : 
  <span><span class="label">env</span>:<span class="xref-unresolved">Eio_unix</span>.Stdenv.base <span class="arrow">&#45;&gt;</span></span>
  <span><span class="label">prompt_file</span>:string <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?session</span>:<a href="../../Session/index.html#type-t">Session.t</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?export_file</span>:string <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?persist_mode</span>:<a href="#type-persist_mode">persist_mode</a> <span class="arrow">&#45;&gt;</span></span>
  <span><span class="optlabel">?parallel_tool_calls</span>:bool <span class="arrow">&#45;&gt;</span></span>
  <span>unit <span class="arrow">&#45;&gt;</span></span>
  unit</span></code></div><div class="spec-doc"><p>Boot the TUI and block until the user terminates the program.</p><p>Calling <code>run_chat ~env ~prompt_file ()</code> is the primary way to start an interactive Ochat session from an executable. The function initialises a full-screen <a href="../../Notty_eio/Term/index.html"><code>Notty_eio.Term</code></a>, parses the ChatMarkdown prompt, builds an initial <a href="../Model/index.html#type-t"><code>Model.t</code></a> and then runs the main event-loop until the user quits.</p><p>On shutdown the helper can:</p><ul><li>optionally export the full conversation as ChatMarkdown (either automatically or after a <code>y/N</code> prompt, depending on how the user exited the UI and the value of <code>?export_file</code>);</li><li>optionally persist the session snapshot according to <code>?persist_mode</code>.</li></ul><ul class="at-tags"><li class="parameter"><span class="at-tag">parameter</span> <span class="value">env</span> <p>The standard environment supplied by <code>Eio_main.run</code>.</p></li></ul><ul class="at-tags"><li class="parameter"><span class="at-tag">parameter</span> <span class="value">prompt_file</span> <p>Path to the <code>*.chatmd*</code> prompt that seeds the conversation, declares tools and configures default model settings.</p></li></ul><ul class="at-tags"><li class="parameter"><span class="at-tag">parameter</span> <span class="value">session</span> <p>Optional persisted session to resume. When present, its history, tasks and key/value store take precedence over the defaults from <code>prompt_file</code>.</p></li></ul><ul class="at-tags"><li class="parameter"><span class="at-tag">parameter</span> <span class="value">export_file</span> <p>Optional override for the ChatMarkdown export path. When omitted the prompt file path is reused.</p></li></ul><ul class="at-tags"><li class="parameter"><span class="at-tag">parameter</span> <span class="value">persist_mode</span> <p>Policy controlling whether the session snapshot is written back on exit. Defaults to <code>`Ask</code>.</p></li></ul><ul class="at-tags"><li class="parameter"><span class="at-tag">parameter</span> <span class="value">parallel_tool_calls</span> <p>Allow multiple tool calls to run in parallel (default: <code>true</code>).</p></li></ul><p>Starting the UI from an executable:</p><pre class="language-ocaml"><code>  let () =
    Eio_main.run @@ fun env -&gt;
    Chat_tui.App.run_chat ~env ~prompt_file:&quot;prompt.chatmd&quot; ()</code></pre><p>Resuming a saved session and exporting to a separate file:</p><pre class="language-ocaml"><code>  let () =
    Eio_main.run @@ fun env -&gt;
    let session = Session_store.load ~env ~id:&quot;my-session-id&quot; in
    Chat_tui.App.run_chat
      ~env
      ~prompt_file:&quot;prompt.chatmd&quot;
      ~session
      ~export_file:&quot;exported.chatmd&quot;
      ~persist_mode:`Always
      ()</code></pre></div></div></div></body></html>
