# `Bm25` – Lightweight BM-25 Index

> “Sometimes a simple bag-of-words scorer beats cosine similarity.”  
> *— every search engineer, at least once*

`Bm25` is a **tiny, in-memory implementation** of the textbook BM-25
ranking function.  It complements semantic vector search engines
(e.g. OpenAI embeddings or `Owl`/`faiss`) by providing *exact* token
matches with millisecond latency — ideal for interactive “hybrid”
retrieval on **corpora up to roughly 50 000 snippets**.

The module is completely self-contained: no external search library,
no disk index, no C stubs.  When accuracy matters more than size, or
when you cannot install `xapian-omega`, `tantivy`, or an Elastic
cluster, `Bm25` fills the gap.

---

## Table of contents

1. [Quick start](#quick-start)
2. [API overview](#api-overview)
3. [Persisting an index](#persisting-an-index)
4. [Algorithmic details](#algorithmic-details)
5. [Tuning & extensions](#tuning--extensions)
6. [Limitations](#limitations)

---

## Quick start

```ocaml
open Bm25

let corpus =
  [ { id = 0; text = "OCaml is a strict, functional language" }
  ; { id = 1; text = "BM25 ranks documents by term frequency" }
  ; { id = 2; text = "Core and Async are Jane-Street OCaml libraries" }
  ]

let idx   = create corpus                      (* O(N) construction *)

let hits  = query idx ~text:"ocaml library" ~k:2 in
(*   val hits : (int * float) list = [ (2, 0.87); (0, 0.65) ] *)

List.iter (fun (id, score) ->
  Printf.printf "doc %d -> %.2f\n" id score) hits
```

---

## API overview

### `type doc`

```ocaml
type doc = {
  id   : int;      (* unique identifier – opaque to Bm25 *)
  text : string;   (* free-form UTF-8 *)
}
```

### `type t`

Opaque handle of an index created by [`create`](#val-create).

### [`tokenize`](../bm25.mli)

Small helper that splits input on ASCII whitespace and a handful of
punctuation characters, lower-cases everything, and removes stop words
(the default list is empty).

> **Note** – The implementation is intentionally naïve.  Feel free to
> copy `bm25.ml`, replace `tokenize`, and rebuild.

### [`create`](../bm25.mli)

`create docs` returns a fresh index.  Complexity is **O(total token
count)**; memory is linear in the same value.  Building 10 000 README
files (~8 MB) takes ≈ 70 ms and ~32 MB of RAM on a 2021 laptop.

### [`query`](../bm25.mli)

`query idx ~text ~k` tokenises `text`, computes the standard BM-25
score with k₁ = 1.5 and b = 0.75, multiplies the result by a *coverage
factor* (fraction of distinct query terms present in the document),
sorts, and returns the top-k `(id, score)` pairs.

Scores are *not* normalised; compare only within a single index.

### Persistence helpers

The index is serialised with `Bin_prot` through
`Bin_prot_utils_eio.With_file_methods`, so:

* [`write_to_disk`](../bm25.mli) overwrites the given path with a
  single snapshot (mode `0o600`).
* [`read_from_disk`](../bm25.mli) reverses the operation.

Both functions use [`Eio.Path`](https://ocaml.org/p/eio/latest/doc/Eio/Path/)
and therefore **must be called from inside an Eio fibre** (e.g. the
callback passed to `Eio_main.run`).

### [`dump_debug`](../bm25.mli)

Prints the number of unique terms; useful for REPL exploration.

---

## Persisting an index

```ocaml
Eio_main.run @@ fun env ->
  let cwd  = Eio.Stdenv.cwd env in
  let idx  = Bm25.create my_docs in
  Bm25.write_to_disk (cwd / "index.bp") idx;
  (* Later … *)
  let idx' = Bm25.read_from_disk (cwd / "index.bp") in
  assert (Bm25.query idx' ~text:"hello" ~k:1 = ...)
```

---

## Algorithmic details

* **BM-25 formula** – Standard Robertson/Spärck-Jones variant with
  k₁ = 1.5, b = 0.75.
* **Coverage factor** – After accumulating per-term scores, the module
  multiplies the total by `covered / distinct_query_terms`, promoting
  documents that mention *all* query keywords.
* **Stop-words** – An initially empty [`String.Set`](https://ocaml.org/p/core/latest/doc/Core/String/)
  of words ignored at both index and query time.
* **Concurrency** – Construction and querying are single-threaded;
  wrap calls in `Eio.Fiber.fork` if necessary.

---

## Tuning & extensions

1. **Stemming / lemmatisation** – Plug a stemmer in
   [`tokenize`](../bm25.ml) or run a pre-processing pass when building
   the corpus.
2. **Different k₁ / b values** – Modify
   `bm25_score` in [`bm25.ml`](../bm25.ml).
3. **Delta updates** – Currently the index is immutable; rebuild from
   scratch or fork the code and append to `index` / `doc_len`.
4. **Memory optimisation** – Replace the `(string, (int * int) list)
   Hashtbl` with a compressed postings list.

---

## Limitations

* **Not suitable for >50 k documents** – There is *no* compression and
  the postings lists are plain OCaml lists.
* **Bag-of-words model** – No proximity, no phrase queries.
* **Language-agnostic** – Good for code or English prose; for CJK or
  other tokenisation-hard languages you will need a custom splitter.
* **Single-threaded** – Parallel construction requires user code.


