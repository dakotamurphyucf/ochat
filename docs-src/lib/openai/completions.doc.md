# `Completions` – Chat Completions API helper

`Completions` is a thin yet powerful wrapper around the
[OpenAI /v1/chat/completions](https://platform.openai.com/docs/api-reference/chat)
endpoint.  It turns strongly-typed OCaml values into the required JSON
payload, performs the HTTPS request over a capability-safe
`Eio.Net.t`, and decodes the server response back into ordinary OCaml
records.

The module is part of the `ochat.openai` library and is implemented
purely in user-land; there are **no C stubs** and no implicit global
state (with the sole exception of the `OPENAI_API_KEY` environment
variable used for authentication).

---

## Quick-start

```ocaml
open Completions

let get_assistant_reply env prompt =
  let net = Eio.Stdenv.net env in
  let dir = Eio.Stdenv.cwd env in

  let user : chat_message =
    { role = "user"
    ; content = Some (Text prompt)
    ; name = None
    ; tool_call_id = None
    ; function_call = None
    ; tool_calls = None
    }
  in

  (* Blocking request: *)
  let ({ message = { content; _ }; _ } : default_choice) =
    post_chat_completion Default ~dir net ~inputs:[ user ]
  in
  Option.value ~default:"" content

(* …in your [Eio_main.run] entry-point: *)

let () =
  Eio_main.run @@ fun env ->
  Printf.printf "%s\n" (get_assistant_reply env "Hello!")
```

---

## API surface

| Item | Description |
|------|-------------|
| `type chat_message` | Single entry in the `messages` array sent to OpenAI |
| `type model` | Enumerated list of supported model aliases |
| `post_chat_completion` | High-level helper (blocking *or* streaming) |
| _Various record types_ | Lossless mirrors of the JSON schema; helpful when dealing with tool-calling and streaming |

For day-to-day usage you only need [`chat_message`] and
[`post_chat_completion`].  The other types are re-exported so that you
can build sophisticated requests without `Obj.magic` or hand-written
Yojson code.

---

## Blocking vs streaming

```ocaml
(* 1. Blocking, returns a [default_choice] when complete: *)
let ({ message; _ } : default_choice) =
  post_chat_completion Default ~dir net ~inputs in

(* 2. Streaming, callback receives each incremental delta: *)
let print_delta { Completions.delta = { content; _ }; _ } =
  Option.iter content ~f:(Printf.printf "%s%!") in

post_chat_completion (Stream print_delta) ~model:Gpt4o ~dir net ~inputs
```

When streaming, `post_chat_completion` returns `unit`.  Any aggregation
must be performed by the caller.

---

## Tool / function calling

OpenAI can be instructed to emit JSON blobs that map onto real OCaml
functions.  The essential pieces are:

```ocaml
let echo_schema =
  { name = "echo"
  ; description = Some "Returns the input string verbatim"
  ; parameters = Jsonaf.of_string "{ \"type\": \"object\", \"properties\": {\n  \"text\": { \"type\": \"string\" } } }"
  }

let tools =
  [ { type_ = "function"; function_ = { echo_schema with strict = true } } ]

let ai_echo net ~dir text =
  let user = { role = "user"; content = Some (Text text); … } in
  post_chat_completion Default ~tools ~dir net ~inputs:[ user ]
```

Refer to the type documentation of [`func`], [`tool_func`] and [`tool`]
for details.

---

## Error handling

* Network errors (`Eio.Net`), TLS failures, or non-2xx HTTP statuses
  propagate as exceptions.
* Invalid JSON from the server raises `Failure` with the raw payload.

Wrap calls with a helper such as `Io.to_res` when explicit error
propagation is desired.

---

## Limitations / roadmap

* Only a subset of model names is enumerated – add new variants as the
  OpenAI platform evolves.
* TLS verification uses `Tls_eio.Config.insecure_no_check` to maximize
  portability; supply your own configuration if strict verification is
  required.
* The module does **not** implement automatic retries or back-pressure
  for rate-limited responses.

---

## Development notes

`completions.ml` is roughly 300 LOC and has **zero external
dependencies** beyond the packages listed in `lib/openai/dune`.  All
JSON codecs are generated by `ppx_jsonaf_conv`.

Patches and suggestions are welcome – please open a PR or file an
issue on the main repository.  Happy hacking!

